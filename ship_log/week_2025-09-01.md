# [SHIP LOG] week: 2025-09-01

## SUMMARY

Week focused on comprehensive performance optimization for the OpenWave quantum physics simulator, implementing critical scaling solutions and architectural improvements.

The work involved consolidating research on Planck mass at Bohr radius to develop a dynamic scaling backend that maintains wave granularity while adapting resolution between Planck scale (1e-35) and energy wave scale (1e-17) based on particle count.

Key architectural enhancements included separating the Physics Engine (a Quantum Physics Engine using Classical Equations per EWT) from the Rendering Engine, achieving significant GPU performance gains demonstrated through 1M particle animation tests, and developing memory optimization strategies with optimized data type bit allocation for billion-particle computations.

The decision was made to prioritize single-machine GPU parallel computing over distributed computing for cost-effectiveness and development focus, with comprehensive documentation created covering all optimization strategies and standards.

Topics Covered:

- Dynamic scaling system with resolution-aware granule mass computation
- Physics/Rendering engine separation architecture
- GPU acceleration methods and performance benchmarking
- Memory optimization for billion-particle simulations
- Single-node vs distributed computing strategy evaluation
- Documentation standards and optimization guidelines

## KEY ACTIVITIES

## PERFORMANCE TOPIC: Dynamic Scaling & Resolution

Modeling a scaling factor for OpenWave that respects dynamic scaling (similarity) and maintain wave granularity (resolution).

This week I'll:

- define a scaling model that re-computes granule mass from planck_mass @bohr_radius / particle count (new scaled spacing)
- implement scaling system as a backend (accessible from any module, @user configurable layer)
- create a clamping factor to max at  planck scale (1e-35) & min at energy_wave (1e-17)

## PERFORMANCE TOPIC: Parallel Processing Optimizations

### 1. Separation of Physics Engine vs. Rendering Engine (computation vs. display)

Separating the logic between our Physics Engine and our Rendering Engine. With this modularity we'll be able to have a Physics Engine that can run large particle count simulations independent of screen rendering constrains, while also having a visual output module whenever needed.

BTW: This Physics Engine is actually a Quantum Physics Engine written with Classical Equations - you talk a lot about this on EWT!

### 2. Continue GPU Optimization

I'm continuing the implementation of GPU optimized computational logic utilizing the Taichi Python acceleration libraries and loop optimization.

To test this approach I used a simplified experiment (particles under force of gravity), the results are:

- on my CPU (16-core): only up to 20,000 particle count
- on my GPU (13 tflops): 1,000,000 particle count (see gif animation below)

![alt text](images/CPUvsGPU.gif)

I think for phase 1 (fundamental particle / neutrino simulations) and our scaling factor, this 1 million particle count is a good resolution, for an universe radius on the magnitude of 10^-16. This gets us 30 particles per wavelength on 3D sims and 300 particles/lambda on 2D sims.

Also, this is our Rendering Engine performance, our Physics Engine can handle 1000x more particle count when not rendering to screen (eg. just computing numerical validations), I was able to compute a 1 billion size array with the GPU optimization.

In the future we can run this code in a more powerful GPU (eg. NVIDIA RXT 5090 with 100 tflops of computing power) without making changes in our code.

### 3. Memory Optimization

Since we're running computation over billions of data-points (granule particles position and velocity vector over time) there are some memory optimization strategies we can adopt.

This week I'll continue to review those memory optimization strategies. I have some ideas that I need to test related to the data type we're using (number of bits of memory allocated per data-point).

This memory and computation optimizations strategy should become the foundation of OpenWave's ability to run large scale simulations.

### 4. Distributed Computing Strategy

I wanted to give you a summary on a decision on how we're handling the distributed computing side of OpenWave.

Instead of jumping right-away into distributed computing (spreading our simulations across multiple computers/servers in the cloud), I'm focusing on getting the most power from a single-machine with powerful GPUs for now.

Distributed computing means renting many computers that work together, but setting that up properly takes large development effort and can easily cost $20,000-50,000 per month just for cloud services. That's not in our budget, and more importantly, it would distract us from actually building the physics simulation itself.
Our current approach is designed for where we are: we're doing "parallel computing optimization" which means optimizing the usage of a single powerful GPU to run calculations simultaneously (eg. many workers in one office instead of coordinating workers across different buildings).

This way, if we need more power, we just buy a better GPU (maybe a few thousand dollars one-time cost, like an NVIDIA GeForce RTX 5090) and our code runs faster without any changes.

Once we have the core simulation working well (with dev community help or eventually some funding), we can then expand to distributed computing for really massive simulations (eg. large protein molecules). But for now, this keeps costs low, development focused, and still gives us plenty of computational power to prove the concepts work.

**Summary:**

- now optimize single-node parallel computing (GPU acceleration)
- future: implement multi-node (distributed) computing with extended scalability

## Documentation & Standards

I've documented the distributed architecture strategy inside the codebase (directory /dev_docs/), including single-node upgrade options analysis and preparations for future multi-node simulation capabilities, with plans for future scaling.

I've also started documenting coding standards guide, loop optimization patterns, performance guidelines and markdown style guides (in the same /dev_docs/ directory).
